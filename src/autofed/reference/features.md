# `features`

---

Implements various helper methods.


## Methods

---

> ```py
> def cluster_by_color(
>   cielab_video: np.ndarray, 
>   masks: np.ndarray, 
>   tolerance=20.0, 
>   kL: int = 1, 
>   kC: int = 1, 
>   kH: int = 1
> ) -> list[TemporalContour]
> ```
>
> Given a video in the CIELAB color space and corresponding masks, this method groups nearby pixels based on 
> perceptive color difference determined by the [CIEDE2000](https://en.wikipedia.org/wiki/Color_difference#CIEDE2000) 
formula:
>
> \\[
>   \Delta E^*_{00} = \sqrt{
>      \left(\frac{\Delta L'}{k_LS_L}\right)^2
>     +\left(\frac{\Delta C'}{k_CS_C}\right)^2
>     +\left(\frac{\Delta H'}{k_HS_H}\right)^2
>     +R_T\frac{\Delta C'}{k_CS_C}\frac{\Delta H'}{k_HS_H}
>    }
> \\]
>
> The result is a list of [temporal contours](/reference/temporal-contour.md), each defining a three-dimensional
> subset of the masks. The lower the `tolerance` (on a scale of [0, 100]), the closer in color pixels must be to
> be grouped together.


> ```py
> def cluster_by_color_in_parallel(
>   rgb_video: np.ndarray, 
>   masks: np.ndarray, 
>   delta=20.0, 
>   kL: int = 1, 
>   kC: int = 1, 
>   kH: int = 1, cpus=4
> ) -> list[TemporalContour]
> ```
>
> Clustering in parallel, see `cluster_by_color` above.

> ```py
> def foreground(video: np.ndarray, background_subtractor) -> np.ndarray
> ```
>
> Feeds each frame of a `video` to a `background_subtractor`, returning a video of the foreground masks generated by
> the subtractor.
>
> `background_subtractor` must be
> * an object with an `apply` method, for example those provided by `open-cv`, `pybgs`, or a custom class, or
> * a function that accepts and returns a `numpy.ndarray`.

> ```py
> def histogram_of_oriented_gradients(
>   video: np.ndarray, 
>   orientations: int = 9, 
>   pixels_per_cell: tuple[int, int] = (8, 8),
>   cels_per_block: tuple[int, int] = (3, 3),
>   block_norm: BlockNorm = "L2-Hys",
>   transform_sqrt: bool = False,
>   channel_axis: Union[int, None] = None
> ) -> np.ndarray
> ```
>
> Computes a 
> [Histogram of Oriented Gradients](https://scikit-image.org/docs/0.25.x/api/skimage.feature.html#skimage.feature.hog) 
> over a video.



> ```py
> def local_binary_pattern(
>   video: np.ndarray, 
>   points: int, 
>   radius: float, 
>   method: str ='default'
> ) -> tuple[np.ndarray, np.ndarray]
> ```
>
> Computes the
> [local binary pattern](https://scikit-image.org/docs/0.25.x/api/skimage.feature.html#skimage.feature.local_binary_pattern) 
> of a video, returning the pair (LBPs, normalized histogram). LBPs will be the frame-by-frame local binary patterns
> and the histogram will result from concatenating the LBPs and normalizing the result.


> ```py
> def regress_to_background(
>   rgba_video: np.ndarray, 
>   background_image: np.ndarray
> ) -> np.ndarray
> ```
>
> Using linear regression and a background reference image, this method estimates the foreground of a video. 
> Both the video and background should be in RGBA format.

> ```py
> def regress_to_background_blocked(
>   rgba_video: np.ndarray, 
>   background_image: np.ndarray, 
>   block_size: int, 
>   overlap: int
> ) -> np.ndarray
> ```
>
> Using linear regression and a background reference image, this method estimates the foreground of a video,
> first subdividing the video into possibly overlapping cubes. Both the video and background should be in 
> RGBA format.

> ```py
> def rgb2mixed(
>     irgb: numpy.ndarray, 
>     sr: float = 0.2126, 
>     sg: float = 0.7152, 
>     sb: float = 0.0722
> ) -> numpy.ndarray
> ```
> 
> Mixes the channels of `irgb` into a single value using red, green, and blue scales
> `sr`, `sg`, `sb`, respectively. The defaults are standard values used in varying
> contexts for grayscale conversion.


> ```py
> def rgb2rgba(image: numpy.ndarray, alpha: int | float) -> numpy.ndarray
> ```
> Adds an `alpha` channel to an RGB `image`.